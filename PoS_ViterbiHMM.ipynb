{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d39e4de9-e3bf-40dc-b473-0f36acab225d",
   "metadata": {},
   "source": [
    "#### PoS tagging per le lingue latino e greco: confronto tra baseline e HMM (Viterbi)\n",
    "Francesco Sannicola"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba1806b-77f7-48a8-83bb-91307a5167d7",
   "metadata": {},
   "source": [
    "- csv per la lettura dei corpus\n",
    "- math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "becc8be0-e113-4fff-a27c-00016c17e50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader as csv_reader\n",
    "from numpy import array as np_array\n",
    "from numpy import delete as np_delete\n",
    "from numpy import empty as np_empty\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2466eaee-1184-479b-bb9f-5c71ad5b3782",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a53711d3-1b6d-4f71-8ae4-889b174cf951",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import MWETokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a27e1a5-ba6a-437c-a207-b1269937e49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainParsing(file):\n",
    "    \n",
    "    #w_e tutte le parole finali\n",
    "    w_e = []\n",
    "    #w_t tutte le parole con proprio tag (+1 per INIT)\n",
    "    w_t = []\n",
    "    # w_s tutte le parole iniziali\n",
    "    w_s= []\n",
    "    \n",
    "    w_t.append(('INIT', 'INIT'))\n",
    "    with open(file) as fd:\n",
    "        rd = csv_reader(fd, delimiter=\"\\t\", quotechar='\"')\n",
    "        i = -1\n",
    "        for row in rd:\n",
    "            if len(row) > 3:\n",
    "                if i == 0:\n",
    "                    w_s.append((row[1].lower(), 'INIT'))\n",
    "                    i = 1\n",
    "                w_t.append((row[1].lower(), row[3].lower()))\n",
    "                last_str = row[1].lower()\n",
    "            if len(row) == 0:\n",
    "                w_e.append((last_str, 'END'))\n",
    "                w_t.append(('END', 'END'))\n",
    "                w_t.append(('INIT', 'INIT'))\n",
    "                i = 0\n",
    "        w_t.pop()\n",
    "    return w_t, w_e, w_s "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c0d57bb-3474-40de-b3de-e42d1cb969ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def devParsing(file):\n",
    "    w_t_dev = []\n",
    "    with open(file) as fd:\n",
    "        rd = csv_reader(fd, delimiter=\"\\t\", quotechar='\"')\n",
    "        for row in rd:\n",
    "            if len(row) > 3:\n",
    "                w_t_dev.append((row[1].lower(), row[3].lower()))\n",
    "    return w_t_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ac5e062-7e79-42fa-8a73-ca4381d972d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testParsing(file):\n",
    "    query_list = []\n",
    "    w_t_test = []\n",
    "    \n",
    "    first_char_init = 9\n",
    " \n",
    "    with open(file) as fd:\n",
    "        rd = csv_reader(fd, delimiter=\"\\t\", quotechar='\"')\n",
    "        i = -1\n",
    "        for row in rd:\n",
    "            if len(row) == 1:\n",
    "                if row[0].startswith('# text'):\n",
    "                    if '...' not in row[0]:\n",
    "                        query_list.append(row[0][first_char_init:(len(row[0]))].lower().replace('.', ' .').replace('路', ' 路'))\n",
    "                    else:\n",
    "                        query_list.append(row[0][first_char_init:(len(row[0]))].lower().replace('路', ' 路'))\n",
    "    \n",
    "            elif len(row) > 3:\n",
    "                w_t_test.append((row[1].lower(), row[3].lower()))\n",
    "    return w_t_test, query_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e066972b-4133-452a-ad4e-d32c1d792028",
   "metadata": {},
   "outputs": [],
   "source": [
    "def singleWordDistribution(w_t_dev):\n",
    "    #obtain tuples word:tag appearing one time\n",
    "    single_occ_word_tag = dict()\n",
    "    single_occ_words = list({key:val for key, val in Counter(i[0] for i in w_t_dev).items() if val == 1})\n",
    "    \n",
    "    u=0\n",
    "    for word in single_occ_words:\n",
    "        for tup in w_t_dev:\n",
    "            if tup[0] == word:\n",
    "                single_occ_word_tag[word] = tup[1]\n",
    "                u+=1\n",
    "                break\n",
    "    \n",
    "    tag_occ_singleoccWord=Counter(single_occ_word_tag.values())\n",
    "    return tag_occ_singleoccWord, single_occ_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bed2018a-a6b4-4686-95b8-c25fb74cf611",
   "metadata": {},
   "outputs": [],
   "source": [
    "greek_train_tree_bank = \"./Bank/Greek/grc_perseus-ud-train.conllu\"\n",
    "latin_train_tree_bank = \"./Bank/Latin/la_llct-ud-train.conllu\"\n",
    "\n",
    "latin_dev_tree_bank = \"./Bank/Latin/la_llct-ud-dev.conllu\"\n",
    "greek_dev_tree_bank = \"./Bank/Greek/grc_perseus-ud-dev.conllu\"\n",
    "\n",
    "greek_test_tree_bank = \"./Bank/Greek/grc_perseus-ud-test.conllu\"\n",
    "latin_test_tree_bank = \"./Bank/Latin/la_llct-ud-test.conllu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bd5c4c3-2f8e-4b61-a3c2-9f23e37fae85",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_t, w_e, w_s = trainParsing(latin_train_tree_bank)\n",
    "w_t_dev = devParsing(latin_dev_tree_bank)\n",
    "w_t_test, query_list = testParsing(latin_test_tree_bank)\n",
    "tag_occ_singleoccWord, single_occ_words = singleWordDistribution(w_t_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ca966d8-b6ee-4cec-aaf0-b8e199f9975c",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_t_occ = Counter(w_t)\n",
    "w_s_occ = Counter(w_s)\n",
    "w_e_occ = Counter(w_e)\n",
    "\n",
    "t_occ = Counter([i[1] for i in w_t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8a1691a-50ba-46b5-b5a7-e4ae0bbe96f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_emission = dict()\n",
    "# compute emission probability\n",
    "# prob w given t\n",
    "for key, value in w_t_occ.items():\n",
    "    prob = value / t_occ.get(key[1])\n",
    "    '''if key[1] in p_emission:\n",
    "        p_emission[key[1]].append([key[0], prob])\n",
    "    else:\n",
    "        p_emission[key[1]] = [[key[0], prob]]'''\n",
    "    if prob == 0:\n",
    "        prob = 0.00001\n",
    "    if key[1] in p_emission:\n",
    "        p_emission[key[1]].update({key[0]: abs(log(prob))})\n",
    "    else:\n",
    "        p_emission[key[1]] = {key[0]: abs(log(prob))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7fb5fe06-3563-4c9e-8d14-b0510d4b1ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_emission_init = dict()\n",
    "#compute emission probability for initial state\n",
    "for key, value in w_s_occ.items():\n",
    "    prob = value / t_occ.get(key[1])\n",
    "    if prob == 0:\n",
    "        prob = 0.00001\n",
    "    if key[1] in p_emission_init:\n",
    "        p_emission_init[key[1]].update({key[0]: abs(log(prob))})\n",
    "    else:\n",
    "        p_emission_init[key[1]] = {key[0]: abs(log(prob))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16d2dc45-2d5c-47d9-ada8-87716c02ab7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_emission_end = dict()\n",
    "#compute emission probability for end state\n",
    "for key, value in w_e_occ.items():\n",
    "    prob = value / t_occ.get(key[1])\n",
    "    if prob == 0:\n",
    "        prob = 0.00001\n",
    "    if key[1] in p_emission_end: \n",
    "        p_emission_end[key[1]].update({key[0]: abs(log(prob))})\n",
    "    else:\n",
    "        p_emission_end[key[1]] = {key[0]: abs(log(prob))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25a8cd8b-8b46-4e97-92b0-c790c0c513c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_transition_dict = dict()\n",
    "# compute transition probability\n",
    "# prob t1 given t\n",
    "for t1 in t_occ.keys():\n",
    "    #if t1 != 'INIT':\n",
    "    for t in t_occ.keys():\n",
    "        count = 0\n",
    "        for i in range(1, len(w_t)):\n",
    "            if w_t[i][1] == t1:\n",
    "                if w_t[i - 1][1] == t:\n",
    "                    count += 1\n",
    "        prob = count / t_occ.get(t)\n",
    "        if prob == 0:\n",
    "            prob = 0.00001\n",
    "        if t in p_transition_dict:\n",
    "            p_transition_dict[t].update({t1: abs(log(prob))})\n",
    "        else:\n",
    "            p_transition_dict[t] = {t1: abs(log(prob))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7648907d-d050-4578-9f9b-2298d1783a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'states = np_array(list(p_transition_dict.keys()))\\nstates = np_delete(states, 0)\\nstates = np_delete(states, 10)'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''states = np_array(list(p_transition_dict.keys()))\n",
    "states = np_delete(states, 0)\n",
    "states = np_delete(states, 10)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5863b2bd-be05-49cb-ac95-b39ecfdca87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "states = np_empty(len(p_transition_dict) - 2 , dtype=object)\n",
    "for key in p_transition_dict.keys():\n",
    "    if str(key) != 'INIT' and str(key) != 'END':\n",
    "        states[i] = str(key)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf48ba24-1c86-4016-8373-11fd7936129e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dptable(V):\n",
    "    yield \" \".join((\"%10d\" % i) for i in range(len(V)))\n",
    "    for y in V[0]:\n",
    "        yield \"%.7s: \" % y+\" \".join(\"%.7s\" % (\"%f\" % v[y]) for v in V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e2d9ab4-dae7-408f-8d77-b3cb33808a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_to_merge = [\n",
    "                 ('[', 'adj', ']'), ('[', 'Adj', ']'),\n",
    "                 ('[', 'adv', ']'), ('[', 'Adv', ']'),\n",
    "                 ('[', 'aux', ']'), ('[', 'Aux', ']'),\n",
    "                 ('[', 'cconj', ']'), ('[', 'Cconj', ']'), \n",
    "                 ('[', 'det', ']'), ('[', 'Det', ']'),\n",
    "                 ('[', 'init', ']'), ('[', 'Init', ']'),\n",
    "                 ('[', 'noun', ']'), ('[', 'Noun', ']'),\n",
    "                 ('[', 'num', ']'), ('[', 'Num', ']'),\n",
    "                 ('[', 'part', ']'), ('[', 'Part', ']'),\n",
    "                 ('[', 'pron', ']'),('[', 'Pron', ']'),\n",
    "                 ('[', 'propn', ']'),('[', 'Propn', ']'),\n",
    "                 ('[', 'punct', ']'),('[', 'Punct', ']'),\n",
    "                 ('[', 'sconj', ']'),('[', 'Sconj', ']'),\n",
    "                 ('[', 'verb', ']'),('[', 'Verb', ']'),\n",
    "                 ('[', 'x', ']'), ('[', 'X', ']'),\n",
    "                 ('[', '--', ']'),\n",
    "                 ('[', 'participle', ']')\n",
    "                 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b69cc2b2-2338-4006-ba8b-d29ebd748824",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = []\n",
    "for value in p_emission.values():\n",
    "    all_words.extend(list(value.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "482189c8-2ebc-44f2-93c2-2223e4edb835",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pos = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7890d0c1-399c-4a6e-ae62-9745fc9c8b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = MWETokenizer(token_to_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9191caa4-d0c9-44d0-b17b-cc113b667a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"for query in query_list:\\n    input_splitted = tokenizer.tokenize(word_tokenize(query))\\n    T = len(input_splitted)\\n    tag_target = 'noun'\\n    for t in range(0, T):\\n        max = 0\\n        for key, value in w_t_occ.items():\\n            if key[0]==input_splitted[t].replace('_', ''):\\n                if max < value:\\n                    max = value\\n                    tag_target = key[1]\\n        all_pos.append([input_splitted[t].replace('_', ''), tag_target])\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BASELINE\n",
    "for query in query_list:\n",
    "    input_splitted = tokenizer.tokenize(word_tokenize(query))\n",
    "    T = len(input_splitted)\n",
    "    tag_target = 'noun'\n",
    "    for t in range(0, T):\n",
    "        max = 0\n",
    "        for key, value in w_t_occ.items():\n",
    "            if key[0]==input_splitted[t].replace('_', ''):\n",
    "                if max < value:\n",
    "                    max = value\n",
    "                    tag_target = key[1]\n",
    "        all_pos.append([input_splitted[t].replace('_', ''), tag_target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4d57ebc7-e95f-4902-8e8e-dcbe95373cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ViterbiHMM(smoothing_mode):\n",
    "    all_pos = []\n",
    "    for query in query_list:\n",
    "            \n",
    "        input_splitted = tokenizer.tokenize(word_tokenize(query))\n",
    "        T = len(input_splitted)\n",
    "        \n",
    "        # Tracking tables from first observation\n",
    "        backtrace=[{}]\n",
    "        for i in states:\n",
    "            try:\n",
    "                backtrace[0][i]=p_transition_dict['INIT'][i]*p_emission_init['INIT'][input_splitted[0]]\n",
    "            except KeyError:\n",
    "                backtrace[0][i]=p_transition_dict['INIT'][i] * 20\n",
    "        \n",
    "        \n",
    "        for t in range(1, T):\n",
    "            input_splitted[t] = input_splitted[t].replace('_', '')\n",
    "            backtrace.append({})\n",
    "            for y in states:\n",
    "                if t == T - 1:\n",
    "                    try:\n",
    "                        (prob, state) = min((backtrace[t-1][y0] * p_transition_dict[y0]['END'] * p_emission[y][input_splitted[t]], y0) for y0 in states)\n",
    "                    except KeyError:\n",
    "                        (prob, state) = min((backtrace[t-1][y0] * p_transition_dict[y0]['END'] * 50, y0) for y0 in states)\n",
    "                else: \n",
    "                    if input_splitted[t] not in all_words:\n",
    "                        \n",
    "                        if smoothing_mode == 1: \n",
    "                            # P(unk|NOUN) =1\n",
    "                            if y == 'noun':\n",
    "                                (prob, state) = min((backtrace[t-1][y0] * p_transition_dict[y0][y] * 0.0001 , y0) for y0 in states)\n",
    "                            else:\n",
    "                                (prob, state) = min((backtrace[t-1][y0] * p_transition_dict[y0][y] * 50, y0) for y0 in states)\n",
    "                                \n",
    "                        elif smoothing_mode == 2:\n",
    "                            # P(unk|NOUN) =0.5 and P(unk|VERB) = 0.5\n",
    "                            if y == 'noun':\n",
    "                                 (prob, state) = min((backtrace[t-1][y0] * p_transition_dict[y0][y] * abs(log(0.5)), y0) for y0 in states)\n",
    "                            elif y == 'verb':\n",
    "                                 (prob, state) = min((backtrace[t-1][y0] * p_transition_dict[y0][y] * abs(log(0.5)), y0) for y0 in states)\n",
    "                            else:\n",
    "                                (prob, state) = min((backtrace[t-1][y0] * p_transition_dict[y0][y] * 50, y0) for y0 in states)\n",
    "                                \n",
    "                        elif smoothing_mode == 3:\n",
    "                            #P(unk|ti) = 1/#(PoS_TAGs)\n",
    "                            (prob, state) = min((backtrace[t-1][y0] * p_transition_dict[y0][y] * abs(log(1 / len(states))), y0) for y0 in states)\n",
    "                            \n",
    "                        elif smoothing_mode == 4:\n",
    "                            #Another smoothing technique based on the dev file and words which appear one time\n",
    "                            for tag in states:\n",
    "                                if y == tag:\n",
    "                                    try:\n",
    "                                        p_emission_new_word = abs(log(tag_occ_singleoccWord[tag] / len(single_occ_words)))\n",
    "                                    except ValueError:\n",
    "                                        p_emission_new_word =  50\n",
    "                                    (prob, state) = min((backtrace[t-1][y0] * p_transition_dict[y0][y] * p_emission_new_word, y0) for y0 in states)\n",
    "                                    break\n",
    "                    else: \n",
    "                        try:\n",
    "                            (prob, state) = min((backtrace[t-1][y0] * p_transition_dict[y0][y] * p_emission[y][input_splitted[t]], y0) for y0 in states)\n",
    "                        except KeyError:\n",
    "                            (prob, state) = min((backtrace[t-1][y0] * p_transition_dict[y0][y] * 50, y0) for y0 in states)\n",
    "                backtrace[t][y] = prob\n",
    "            #for i in dptable(viterbi):\n",
    "            #   print (i)\n",
    "            opt=[]\n",
    "            for j in backtrace:\n",
    "                for x,y in j.items():\n",
    "                    if j[x]==min(j.values()):\n",
    "                        opt.append(x)\n",
    "        # print ('The PoS are\\n'+''\n",
    "        #       .join(map(''.join, zip([x + '/' for x in input_splitted], [x + '\\n' for x in opt])))\n",
    "        #       +'\\nWith probability of %s'%p)\n",
    "        for l in range(0,T):\n",
    "            all_pos.append([input_splitted[l].replace('_', ''), opt[l]])\n",
    "    return all_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "83c540f5-fa1b-4a1a-a6d9-10f9bf629968",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'sortstates'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-eee737519bda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mViterbiHMM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-39-c7e809974c85>\u001b[0m in \u001b[0;36mViterbiHMM\u001b[0;34m(smoothing_mode)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m# Tracking tables from first observation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mbacktrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msortstates\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0mbacktrace\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp_transition_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'INIT'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mp_emission_init\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'INIT'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_splitted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m                 raise AttributeError(\"module {!r} has no attribute \"\n\u001b[0;32m--> 215\u001b[0;31m                                      \"{!r}\".format(__name__, attr))\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__dir__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'sortstates'"
     ]
    }
   ],
   "source": [
    "all_pos = ViterbiHMM(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ec5ec879-9b13-46b4-9908-539a71f93f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "same = 0\n",
    "\n",
    "for i in range(0, len(all_pos)):\n",
    "    if all_pos[i][0] == w_t_test[i][0]:\n",
    "        same+=1\n",
    "    else:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "569893c4-a757-4475-8808-24aff87f752b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9417334606918892\n",
      "22676\n",
      "1403\n"
     ]
    }
   ],
   "source": [
    "right_pos = 0\n",
    "wrong_pos = 0\n",
    "n = 0\n",
    "\n",
    "for word in all_pos:\n",
    "    if (word[1] == w_t_test[n][1]):\n",
    "        right_pos +=1\n",
    "    else :\n",
    "        wrong_pos +=1\n",
    "    n += 1\n",
    "\n",
    "accuracy = right_pos/(right_pos+wrong_pos)\n",
    "\n",
    "print(accuracy)\n",
    "print(right_pos)\n",
    "print(wrong_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "85541241-2846-4504-888d-7aae6391fee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['punct', 'adp', 'propn', 'noun', 'verb', 'det', 'cconj', 'pron',\n",
       "       'adj', 'num', 'aux', 'sconj', 'adv', 'part', 'x'], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "73d9313a-62e4-4b90-977f-091a8fd0117d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['adj', 'adp', 'adv', 'aux', 'cconj', 'det', 'noun', 'num', 'part',\n",
       "       'pron', 'propn', 'punct', 'sconj', 'verb', 'x'], dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124e6bee-91e0-4d15-9df0-11cf0ffa76d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
