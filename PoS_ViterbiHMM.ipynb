{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d39e4de9-e3bf-40dc-b473-0f36acab225d",
   "metadata": {},
   "source": [
    "#### PoS tagging per latino e greco: confronto tra baseline e HMM (Viterbi)\n",
    "Francesco Sannicola"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba1806b-77f7-48a8-83bb-91307a5167d7",
   "metadata": {},
   "source": [
    "Librerie utilizzate:\n",
    "\n",
    "- csv per la lettura dei corpus\n",
    "- math per utilizzare la funzione logaritmo\n",
    "- numpy, esattamente i moduli array, delete, empty. Vedremo una sola struttura utilizzare questi moduli\n",
    "- time per il monitoraggio e il confronto dei tempi di esecuzione delle due strategie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "becc8be0-e113-4fff-a27c-00016c17e50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader as csv_reader\n",
    "from numpy import array as np_array\n",
    "from numpy import delete as np_delete\n",
    "from numpy import empty as np_empty\n",
    "from math import log\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6be173-8783-4ce4-acc2-0c73b3f76c62",
   "metadata": {},
   "source": [
    "- Counter permetterà di contare le occorrenze di uno stesso elemento all'interno di una struttura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2466eaee-1184-479b-bb9f-5c71ad5b3782",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337f28be-e01b-4142-9ce8-55ae90bb0c07",
   "metadata": {},
   "source": [
    "- word_tokenize sarà utilizzato per estrarre le parole dalle frasi in input\n",
    "- MWETokenizer permetterà di effettuare un preprocessing ai token (solo nel latino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a53711d3-1b6d-4f71-8ae4-889b174cf951",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import MWETokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5275d549-ffd3-48d2-a4ad-1cea0f08ef38",
   "metadata": {},
   "source": [
    "Il metodo trainParsing(file) ha come input il file train del corpus.\n",
    "\n",
    "In output avremo le coppie (parola, tag) lette dal file più le coppie (parola, INIT) e (parola, END).\n",
    "La struttura utilizzata, in questo caso, è la lista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a27e1a5-ba6a-437c-a207-b1269937e49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainParsing(file):\n",
    "    \n",
    "    #w_e tutte le parole finali\n",
    "    w_e = []\n",
    "    #w_t tutte le parole con proprio tag più i delimitatori END e INIT\n",
    "    w_t = []\n",
    "    # w_s tutte le parole iniziali\n",
    "    w_s= []\n",
    "    \n",
    "    w_t.append(('INIT', 'INIT'))\n",
    "    with open(file) as fd:\n",
    "        rd = csv_reader(fd, delimiter=\"\\t\", quotechar='\"')\n",
    "        i = -1\n",
    "        for row in rd:\n",
    "            if len(row) > 3:\n",
    "                if i == 0:\n",
    "                    w_s.append((row[1].lower(), 'INIT'))\n",
    "                    i = 1\n",
    "                w_t.append((row[1].lower(), row[3].lower()))\n",
    "                last_str = row[1].lower()\n",
    "            if len(row) == 0:\n",
    "                w_e.append((last_str, 'END'))\n",
    "                w_t.append(('END', 'END'))\n",
    "                w_t.append(('INIT', 'INIT'))\n",
    "                i = 0\n",
    "        w_t.pop()\n",
    "    return w_t, w_e, w_s "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3837c5-4dc6-4f22-b60b-779abf44c09a",
   "metadata": {},
   "source": [
    "Calocolo le coppie (parola, tag) dal file dev."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c0d57bb-3474-40de-b3de-e42d1cb969ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def devParsing(file):\n",
    "    w_t_dev = []\n",
    "    with open(file) as fd:\n",
    "        rd = csv_reader(fd, delimiter=\"\\t\", quotechar='\"')\n",
    "        for row in rd:\n",
    "            if len(row) > 3:\n",
    "                w_t_dev.append((row[1].lower(), row[3].lower()))\n",
    "    return w_t_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67d1f9f-656b-4761-9d2b-7a228cc45fa1",
   "metadata": {},
   "source": [
    "Parsing del file test:\n",
    "- calcolo coppie (parola, tag)\n",
    "- calcolo e parsificazione (solo per latino) delle frasi su cui testare gli algoritmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ac5e062-7e79-42fa-8a73-ca4381d972d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testParsing(file):\n",
    "    query_list = []\n",
    "    w_t_test = []\n",
    "    \n",
    "    first_char_init = 9\n",
    " \n",
    "    with open(file) as fd:\n",
    "        rd = csv_reader(fd, delimiter=\"\\t\", quotechar='\"')\n",
    "        i = -1\n",
    "        for row in rd:\n",
    "            if len(row) == 1:\n",
    "                if row[0].startswith('# text'):\n",
    "                    if '...' not in row[0]:\n",
    "                        query_list.append(row[0][first_char_init:(len(row[0]))].lower().replace('.', ' .').replace('·', ' ·'))\n",
    "                    else:\n",
    "                        query_list.append(row[0][first_char_init:(len(row[0]))].lower().replace('·', ' ·'))\n",
    "    \n",
    "            elif len(row) > 3:\n",
    "                w_t_test.append((row[1].lower(), row[3].lower()))\n",
    "    return w_t_test, query_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df862b1d-c465-4c85-8a4d-d916ec0c944d",
   "metadata": {},
   "source": [
    "Percorso relativo dei corpus (test, dev, train)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bed2018a-a6b4-4686-95b8-c25fb74cf611",
   "metadata": {},
   "outputs": [],
   "source": [
    "greek_train_tree_bank = \"./Bank/Greek/grc_perseus-ud-train.conllu\"\n",
    "latin_train_tree_bank = \"./Bank/Latin/la_llct-ud-train.conllu\"\n",
    "\n",
    "latin_dev_tree_bank = \"./Bank/Latin/la_llct-ud-dev.conllu\"\n",
    "greek_dev_tree_bank = \"./Bank/Greek/grc_perseus-ud-dev.conllu\"\n",
    "\n",
    "greek_test_tree_bank = \"./Bank/Greek/grc_perseus-ud-test.conllu\"\n",
    "latin_test_tree_bank = \"./Bank/Latin/la_llct-ud-test.conllu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3736a62f-e134-4357-968e-f3cc6636c640",
   "metadata": {
    "tags": []
   },
   "source": [
    "Metodo utilizzato più avanti per il quarto metodo di smoothing.\n",
    "\n",
    "Sono necessari in input le coppie (parola, tag) appartenenti al file ***dev***.\n",
    "\n",
    "Vengono calcolate e restituite in output:\n",
    "- le parole che appaiono una sola volta\n",
    "- le coppie (parola, tag) per le parole che compaiono una sola volta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e066972b-4133-452a-ad4e-d32c1d792028",
   "metadata": {},
   "outputs": [],
   "source": [
    "def singleWordDistribution(w_t_dev):\n",
    "    #obtain tuples word:tag appearing one time\n",
    "    single_occ_word_tag = dict()\n",
    "    single_occ_words = list({key:val for key, val in Counter(i[0] for i in w_t_dev).items() if val == 1})\n",
    "    \n",
    "    u=0\n",
    "    for word in single_occ_words:\n",
    "        for tup in w_t_dev:\n",
    "            if tup[0] == word:\n",
    "                single_occ_word_tag[word] = tup[1]\n",
    "                u+=1\n",
    "                break\n",
    "    \n",
    "    tag_occ_singleoccWord=Counter(single_occ_word_tag.values())\n",
    "    return tag_occ_singleoccWord, single_occ_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91941e93-cd4d-4884-8387-e1e51081eb35",
   "metadata": {},
   "source": [
    "Attraverso Counter effettuo il conteggio delle occorenze delle coppie (parola, tag) per le tre strutture.\n",
    "Avremo, quindi, un oggetto Counter molto simile ad un dizionario: le coppie (parola, tag) come chiave e il relativo conteggio come valore.\n",
    "\n",
    "Per ogni tag viene calcolato, inoltre, il numero di volte che appare nel corpus del file train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ca966d8-b6ee-4cec-aaf0-b8e199f9975c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeOcc(w_t, w_s, w_e):\n",
    "    w_t_occ = Counter(w_t)\n",
    "    w_s_occ = Counter(w_s)\n",
    "    w_e_occ = Counter(w_e)\n",
    "\n",
    "    t_occ = Counter([i[1] for i in w_t])\n",
    "    \n",
    "    return w_t_occ, w_s_occ, w_e_occ, t_occ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc81a52-874e-4e4b-a552-084ed0254808",
   "metadata": {},
   "source": [
    "Probabilità di emissione:\n",
    "  $$\n",
    "  p(w|t) = \\frac{P(t,w)}{P(t)}.\n",
    "  $$\n",
    " \n",
    "Come accennato in precedenza useremo la funzione logaritmo per evitare eventuali underflow dovute a probabilità estremamente basse.\n",
    "  $$\n",
    "  log(p(w|t))\n",
    "  $$\n",
    "La funzione logaritmo restituirà sempre un valore minore o uguale a 0. Più l'evento è probabile e più il logaritmo è vicino allo zero.\n",
    "Nel caso che la probabilità fosse uguale a 0 e che la funzione logaritmo non sia applicabile a questo valore, si assegna alla probabilità un valore molto vicino allo zero (nel nostro caso 0.00001)\n",
    "\n",
    "Dopo una serie di sperimentazioni è stato scelto di applicare il valore assoluto alla funzione logaritmo in modo di lavorare sempre con valori positivi.\n",
    "  $$\n",
    "  |log(p(w|t))|\n",
    "  $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8a1691a-50ba-46b5-b5a7-e4ae0bbe96f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeEmission(w_t_occ, t_occ):\n",
    "    p_emission = dict()\n",
    "    # prob w given t\n",
    "    for key, value in w_t_occ.items():\n",
    "        prob = value / t_occ.get(key[1])\n",
    "        if prob == 0:\n",
    "            prob = 0.00001\n",
    "        if key[1] in p_emission:\n",
    "            p_emission[key[1]].update({key[0]: abs(log(prob))})\n",
    "        else:\n",
    "            p_emission[key[1]] = {key[0]: abs(log(prob))}\n",
    "    return  p_emission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce66da2-65bf-4267-89ff-a0acbb9544b6",
   "metadata": {},
   "source": [
    "Calcolo probabilità di emissione per le parole iniziali."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fb5fe06-3563-4c9e-8d14-b0510d4b1ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeEmissionInit(w_s_occ, t_occ):\n",
    "    p_emission_init = dict()\n",
    "    #compute emission probability for initial state\n",
    "    for key, value in w_s_occ.items():\n",
    "        prob = value / t_occ.get(key[1])\n",
    "        if prob == 0:\n",
    "            prob = 0.00001\n",
    "        if key[1] in p_emission_init:\n",
    "            p_emission_init[key[1]].update({key[0]: abs(log(prob))})\n",
    "        else:\n",
    "            p_emission_init[key[1]] = {key[0]: abs(log(prob))}\n",
    "    return p_emission_init"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6ec6d7-a11c-4cef-aff6-bc235de09fd4",
   "metadata": {},
   "source": [
    "Calcolo probabilità di emissione per le parole finali."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16d2dc45-2d5c-47d9-ada8-87716c02ab7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeEmissionEnd(w_e_occ, t_occ):\n",
    "    p_emission_end = dict()\n",
    "    #compute emission probability for end state\n",
    "    for key, value in w_e_occ.items():\n",
    "        prob = value / t_occ.get(key[1])\n",
    "        if prob == 0:\n",
    "            prob = 0.00001\n",
    "        if key[1] in p_emission_end: \n",
    "            p_emission_end[key[1]].update({key[0]: abs(log(prob))})\n",
    "        else:\n",
    "            p_emission_end[key[1]] = {key[0]: abs(log(prob))}\n",
    "    return p_emission_end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839b73a9-a64c-4daa-a370-f07cfcdc0e2d",
   "metadata": {},
   "source": [
    "Probabilità di transizione:\n",
    "  $$\n",
    "  p(t_1|t) = \\frac{P(t,t_1)}{P(t)}.\n",
    "  $$\n",
    "  \n",
    "Anche in questo caso consideremo il valore assoluto del logaritmo della probabilità:\n",
    "  $$\n",
    "  |log(p(t_1|t))|\n",
    "  $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25a8cd8b-8b46-4e97-92b0-c790c0c513c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTransition(w_t, t_occ):\n",
    "    p_transition_dict = dict()\n",
    "    # prob t1 given t\n",
    "    for t1 in t_occ.keys():\n",
    "        for t in t_occ.keys():\n",
    "            count = 0\n",
    "            for i in range(1, len(w_t)):\n",
    "                if w_t[i][1] == t1:\n",
    "                    if w_t[i - 1][1] == t:\n",
    "                        count += 1\n",
    "            prob = count / t_occ.get(t)\n",
    "            if prob == 0:\n",
    "                prob = 0.00001\n",
    "            if t in p_transition_dict:\n",
    "                p_transition_dict[t].update({t1: abs(log(prob))})\n",
    "            else:\n",
    "                p_transition_dict[t] = {t1: abs(log(prob))}\n",
    "    return p_transition_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91fed68-26c9-4e9b-b055-f631f2acd2f6",
   "metadata": {},
   "source": [
    "Calcolo tutti i possibili states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5863b2bd-be05-49cb-ac95-b39ecfdca87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStates(p_transition_dict):\n",
    "    i = 0\n",
    "    states = np_empty(len(p_transition_dict) - 2 , dtype=object)\n",
    "    for key in t_occ.keys():\n",
    "        if str(key) != 'INIT' and str(key) != 'END':\n",
    "            states[i] = str(key)\n",
    "            i += 1\n",
    "    return states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa4a651-4254-4613-b2ee-fb2126604063",
   "metadata": {},
   "source": [
    "Ottengo tutte le parole presenti nel corpus train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b69cc2b2-2338-4006-ba8b-d29ebd748824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCorpusWords(p_emission):\n",
    "    all_words = []\n",
    "    for value in p_emission.values():\n",
    "        all_words.extend(list(value.keys()))\n",
    "    return all_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b830877-2d34-44bd-9003-de4804ee570c",
   "metadata": {},
   "source": [
    "Una volta popolata la lista contentente i PoS calcolati è possibile andare a calcolare l'accuratezza, PoS corretti ed errati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "569893c4-a757-4475-8808-24aff87f752b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateAccuracy(all_pos, w_t_test):\n",
    "    right_pos = 0\n",
    "    wrong_pos = 0\n",
    "    n = 0\n",
    "\n",
    "    for word in all_pos:\n",
    "        if (word[1] == w_t_test[n][1]):\n",
    "            right_pos +=1\n",
    "        else :\n",
    "            wrong_pos +=1\n",
    "        n += 1\n",
    "\n",
    "    accuracy = right_pos/(right_pos+wrong_pos)\n",
    "\n",
    "    print(\"Right PoS: %s\" % right_pos)\n",
    "    print(\"Wrong PoS: %s\" % wrong_pos)\n",
    "    print(\"Accuracy: %s\" % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8275ade8-d761-428f-98d0-bd65f913c91f",
   "metadata": {},
   "source": [
    "Controllo se le parole all'interno di *all_pos* e la lista *w_t_test* combaciano esattamente (utile per debugging)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec5ec879-9b13-46b4-9908-539a71f93f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkWrongWords(all_pos, w_t_test):\n",
    "    same = 0\n",
    "    for i in range(0, len(all_pos)):\n",
    "        if all_pos[i][0] == w_t_test[i][0]:\n",
    "            same+=1\n",
    "        else:\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ad5173-b369-49ff-ad51-41cebc5d21a6",
   "metadata": {},
   "source": [
    "All'interno del corpus per la lingua latina sono presenti delle parole come *\"[adj]\"* o *\"[--]\"* che necessitano un trattamento diverso rispetto alle altre. Le funzioni *.split()* oppure *word_tokenize* di nltk non sono in grado di ottenere il token corretto. Per esempio la singola parola *\"[--]\"* viene suddivisa in *\"[\"*, *\"--\"* e *\"]\"*\n",
    "\n",
    "Ci sono possibili soluzioni:\n",
    "\n",
    "- non considerarle perchè potrebbero essere degli errori o delle annotazioni. Inoltre ne sono presenti in una percentuale veramente ridotta considerando il numero totale di parole e che non ifluisce più di tanto sull'inferenza\n",
    "- trovare una metodologia che forzi la corretta tokenizzazione\n",
    "\n",
    "E' stato deciso di implementare una strategia che permetta la corretta tokenizzazione.\n",
    "La variabile a seguire specifica tutti i token da processare in modo diverso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e2d9ab4-dae7-408f-8d77-b3cb33808a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_to_merge = [\n",
    "                 ('[', 'adj', ']'), ('[', 'Adj', ']'),\n",
    "                 ('[', 'adv', ']'), ('[', 'Adv', ']'),\n",
    "                 ('[', 'aux', ']'), ('[', 'Aux', ']'),\n",
    "                 ('[', 'cconj', ']'), ('[', 'Cconj', ']'), \n",
    "                 ('[', 'det', ']'), ('[', 'Det', ']'),\n",
    "                 ('[', 'init', ']'), ('[', 'Init', ']'),\n",
    "                 ('[', 'noun', ']'), ('[', 'Noun', ']'),\n",
    "                 ('[', 'num', ']'), ('[', 'Num', ']'),\n",
    "                 ('[', 'part', ']'), ('[', 'Part', ']'),\n",
    "                 ('[', 'pron', ']'),('[', 'Pron', ']'),\n",
    "                 ('[', 'propn', ']'),('[', 'Propn', ']'),\n",
    "                 ('[', 'punct', ']'),('[', 'Punct', ']'),\n",
    "                 ('[', 'sconj', ']'),('[', 'Sconj', ']'),\n",
    "                 ('[', 'verb', ']'),('[', 'Verb', ']'),\n",
    "                 ('[', 'x', ']'), ('[', 'X', ']'),\n",
    "                 ('[', '--', ']'),\n",
    "                 ('[', 'participle', ']')\n",
    "                 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf5401d-ddf8-45b3-b884-d7fb36a0b1e4",
   "metadata": {},
   "source": [
    "Creo una istanza di oggetto di MWETokenizer passando i token su cui non fare lo split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7890d0c1-399c-4a6e-ae62-9745fc9c8b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = MWETokenizer(token_to_merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39a8a24-0bf4-400d-b2ef-f17738e793ac",
   "metadata": {},
   "source": [
    "Metodo che consente di stampare la tabella di Viterbi (usato principalmente per debugging)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf48ba24-1c86-4016-8373-11fd7936129e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dptable(V):\n",
    "    yield \" \".join((\"%10d\" % i) for i in range(len(V)))\n",
    "    for y in V[0]:\n",
    "        yield \"%.7s: \" % y+\" \".join(\"%.7s\" % (\"%f\" % v[y]) for v in V)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ecba99-f887-4fbc-9e64-e5d0b1d593df",
   "metadata": {},
   "source": [
    "## Implementazione metodo di Viterbi\n",
    "### Hidden Markov Model e programmazione dinamica.\n",
    "\n",
    "In input è necessario specificare la tecnica di smoothing:\n",
    "\n",
    "- 1: consideriamo tutte le parole sconosciute dei *noun*   \n",
    "  $$\n",
    "      P(unk|NOUN) =1\n",
    "  $$\n",
    "- 2: consideriamo tutte le parole sconosciute dei *noun* oppure dei *verb* con la stessa probabilità   \n",
    "  $$\n",
    "      P(unk|NOUN) =0.5 \\ and \\ P(unk|VERB) = 0.5\n",
    "  $$\n",
    "- 3: consideriamo le parole sconosciute con una probabilità che dipende dal numero di states (numero di tag)\n",
    "  $$\n",
    "      P(unk|t_i) = 1/(number \\ of \\ PoS \\ Tags)\n",
    "  $$\n",
    "- 4: tagghiamo le parole sconosciute secondo la distribuzione di parole che appaiono una sola volta all'interno del *dev corpus* calcolata precedentemente.\n",
    "  $$\n",
    "      P(unk|t_i) = (number \\ of \\ words \\ appear \\ one \\ time \\ tagged \\ with \\ t_i)/(number \\ of \\ words \\ appear \\ one \\ time)\n",
    "  $$\n",
    "  \n",
    " \n",
    "In output avremo la lista *all_pos* contentente tutte le coppie (parola, tag) frutto delle computazioni.\n",
    "\n",
    "\n",
    "Il primo for effettua un ciclo su tutte le frasi in input prese dal corpus test. Dopodichè si procede nel parsing della frase attraverso il MWETokenizer istanziato precedentemente e che risolverà i problemi relativi allo splitting di parole che in realtà non andrebbero divise.\n",
    "\n",
    "Possiamo ora iniziare con il cosidetto ***Inizialization step***: il secondo for che vediamo in questo metodo si occupa di inizializzare la matrice di Viterbi (in questo caso chiamata backtrace) con le probabilità di transizione da *INIT* allo stato i-esimo moltiplicata per la probabilità che quella parola sia iniziale. Nel caso non si abbia mai visto quella parola come la prima di una frase allora si moltiplica per un valore abbastanza alto (20). \n",
    "\n",
    "Da quest'ultima operazione possiamo iniziare a capire che, a differenza dell'algoritmo di Viterbi classico il quale punta nel massimizzare il risultato del prodotto tra probabilità di transizione e di emissione, l'obiettivo ora è minimizzare.\n",
    "Ricordiamo che tutti i valori di probabilità sono stati applicati alla funzione logaritmo e successivamente alla funzione valore assoluto. Così facendo avremo valori alti nel caso di probabilità basse.\n",
    "Perciò il nome delle variabili potrebbe trarre in inganno: non parliamo di probabilità ma di valori alti in caso di probabilità tendendi allo 0 e di valori bassi per probabilità tendenti a 1.\n",
    "\n",
    "\n",
    "Passiamo ora al ***recursion step***: consideriamo ora dalla seconda parola fino all'ultima.\n",
    "Effettuiamo un ultimo passo di processing della stringa andando a togliere eventuali *\"_\"* dalle parole dovuto all'esecuzione di MWETokenizer.\n",
    "Anche in questo caso cicliamo su ogni stato e andiamo a popolare la matrice di viterbi andando a considerare il ***minimo*** prodotto tra la matrice di viterbi del livello precedente e la probabilità di transizione ed emissione.\n",
    "Se la parola attualmente in esame è sconosciuta allora procediamo nell'esecuzione di una tecnica di smoothing. Invece, se una parola è conosciuta, ma non è mai stata taggata con un particolare tag (scopo del except KeyError) allora andremo ad moltiplicare per un valore alto (50).\n",
    "\n",
    "Il ***termination step*** si occupa di scegliere un tag per l'ultima parola della frase minimizzando il prodotto tra la matrice al livello precendete, la probabilità di transizione dallo stato attuale allo stato finale e la probabilità che quella parola sia finale.\n",
    "\n",
    "Effettuato il ***termination step***, grazie alla matrice che abbiamo costruito nei passi precedenti, possiamo calcolare i PoS più probabili.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d57ebc7-e95f-4902-8e8e-dcbe95373cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ViterbiHMM(p_emission, p_emission_init, p_transition, query_list, smoothing_mode, tag_occ_singleoccWord = None, single_occ_words = None):\n",
    "    all_pos = []\n",
    "    for query in query_list:\n",
    "            \n",
    "        input_splitted = tokenizer.tokenize(word_tokenize(query))\n",
    "        T = len(input_splitted)\n",
    "        \n",
    "        # Tracking tables from first observation (Inizialization step)\n",
    "        backtrace=[{}]\n",
    "        for i in states:\n",
    "            try:\n",
    "                backtrace[0][i]=p_transition['INIT'][i]*p_emission_init['INIT'][input_splitted[0]]\n",
    "            except KeyError:\n",
    "                backtrace[0][i]=p_transition['INIT'][i] * 20\n",
    "        \n",
    "        \n",
    "        for t in range(1, T):\n",
    "            input_splitted[t] = input_splitted[t].replace('_', '')\n",
    "            backtrace.append({})\n",
    "            for y in states:\n",
    "                #Termination step\n",
    "                if t == T - 1:\n",
    "                    try:\n",
    "                        (prob, state) = min((backtrace[t-1][y0] * p_transition[y0]['END'] * p_emission[y][input_splitted[t]], y0) for y0 in states)\n",
    "                    except KeyError:\n",
    "                        (prob, state) = min((backtrace[t-1][y0] * p_transition[y0]['END'] * 50, y0) for y0 in states)\n",
    "                else: \n",
    "                    if input_splitted[t] not in all_words:\n",
    "                        \n",
    "                        if smoothing_mode == 1: \n",
    "                            # P(unk|NOUN) =1\n",
    "                            if y == 'noun':\n",
    "                                (prob, state) = min((backtrace[t-1][y0] * p_transition[y0][y] * 0.0001 , y0) for y0 in states)\n",
    "                            else:\n",
    "                                (prob, state) = min((backtrace[t-1][y0] * p_transition[y0][y] * 50, y0) for y0 in states)\n",
    "                                \n",
    "                        elif smoothing_mode == 2:\n",
    "                            # P(unk|NOUN) =0.5 and P(unk|VERB) = 0.5\n",
    "                            if y == 'noun':\n",
    "                                 (prob, state) = min((backtrace[t-1][y0] * p_transition[y0][y] * abs(log(0.5)), y0) for y0 in states)\n",
    "                            elif y == 'verb':\n",
    "                                 (prob, state) = min((backtrace[t-1][y0] * p_transition[y0][y] * abs(log(0.5)), y0) for y0 in states)\n",
    "                            else:\n",
    "                                (prob, state) = min((backtrace[t-1][y0] * p_transition[y0][y] * 50, y0) for y0 in states)\n",
    "                                \n",
    "                        elif smoothing_mode == 3:\n",
    "                            #P(unk|ti) = 1/#(PoS_TAGs)\n",
    "                            (prob, state) = min((backtrace[t-1][y0] * p_transition[y0][y] * abs(log(1 / len(states))), y0) for y0 in states)\n",
    "                            \n",
    "                        elif smoothing_mode == 4:\n",
    "                            #Another smoothing technique based on the dev file and words which appear one time\n",
    "                            for tag in states:\n",
    "                                if y == tag:\n",
    "                                    try:\n",
    "                                        p_emission_new_word = abs(log(tag_occ_singleoccWord[tag] / len(single_occ_words)))\n",
    "                                    except ValueError:\n",
    "                                        p_emission_new_word =  50\n",
    "                                    (prob, state) = min((backtrace[t-1][y0] * p_transition[y0][y] * p_emission_new_word, y0) for y0 in states)\n",
    "                                    break\n",
    "                        else :\n",
    "                            return\n",
    "                    else: \n",
    "                        try:\n",
    "                            (prob, state) = min((backtrace[t-1][y0] * p_transition[y0][y] * p_emission[y][input_splitted[t]], y0) for y0 in states)\n",
    "                        except KeyError:\n",
    "                            (prob, state) = min((backtrace[t-1][y0] * p_transition[y0][y] * 50, y0) for y0 in states)\n",
    "                backtrace[t][y] = prob\n",
    "            #for i in dptable(viterbi):\n",
    "            #   print (i)\n",
    "            opt=[]\n",
    "            for j in backtrace:\n",
    "                for x,y in j.items():\n",
    "                    if j[x]==min(j.values()):\n",
    "                        opt.append(x)\n",
    "        # print ('The PoS are\\n'+''\n",
    "        #       .join(map(''.join, zip([x + '/' for x in input_splitted], [x + '\\n' for x in opt]))))\n",
    "        for l in range(0,T):\n",
    "            all_pos.append([input_splitted[l].replace('_', ''), opt[l]])\n",
    "    return all_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfa3956-4e36-46b1-8271-5e53acf2d41c",
   "metadata": {},
   "source": [
    "### Implementazione baseline\n",
    "Semplice algoritmo basato sul numero di volte che una certa parola, all'interno del train set, appare con un determinato tag.\n",
    "Assegno alle parola in ingresso il tag con cui essa appare più volte all'interno del *train*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9191caa4-d0c9-44d0-b17b-cc113b667a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Baseline(w_t_occ, query_list):\n",
    "    all_pos=[]\n",
    "    for query in query_list:\n",
    "        input_splitted = tokenizer.tokenize(word_tokenize(query))\n",
    "        T = len(input_splitted)\n",
    "        tag_target = 'noun'\n",
    "        for t in range(0, T):\n",
    "            max = 0\n",
    "            for key, value in w_t_occ.items():\n",
    "                if key[0]==input_splitted[t].replace('_', ''):\n",
    "                    if max < value:\n",
    "                        max = value\n",
    "                        tag_target = key[1]\n",
    "            all_pos.append([input_splitted[t].replace('_', ''), tag_target])\n",
    "    return all_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108c9434-544a-460c-8dbc-440422fe22c2",
   "metadata": {},
   "source": [
    "## Latino "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "83c540f5-fa1b-4a1a-a6d9-10f9bf629968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 4.02 seconds (Calculate probability - latin) ---\n",
      "--- 31.06 seconds (Viterbi, 1st smoothing - latin) ---\n",
      "Right PoS: 22353\n",
      "Wrong PoS: 1726\n",
      "Accuracy: 0.9283192823622244\n",
      "--- 30.97 seconds (Viterbi, 2nd smoothing - latin) ---\n",
      "Right PoS: 22393\n",
      "Wrong PoS: 1686\n",
      "Accuracy: 0.9299804809169816\n",
      "--- 31.19 seconds (Viterbi, 3th smoothing - latin) ---\n",
      "Right PoS: 22436\n",
      "Wrong PoS: 1643\n",
      "Accuracy: 0.9317662693633456\n",
      "--- 31.11 seconds (Viterbi, 4th smoothing - latin) ---\n",
      "Right PoS: 22676\n",
      "Wrong PoS: 1403\n",
      "Accuracy: 0.9417334606918892\n"
     ]
    }
   ],
   "source": [
    "w_t, w_e, w_s = trainParsing(latin_train_tree_bank)\n",
    "w_t_dev = devParsing(latin_dev_tree_bank)\n",
    "w_t_test, query_list = testParsing(latin_test_tree_bank)\n",
    "\n",
    "tag_occ_singleoccWord, single_occ_words = singleWordDistribution(w_t_dev)\n",
    "\n",
    "w_t_occ, w_s_occ, w_e_occ, t_occ = computeOcc(w_t, w_s, w_e)\n",
    "\n",
    "start_time = time.time()\n",
    "p_emission = computeEmission(w_t_occ, t_occ)\n",
    "p_emission_init = computeEmissionInit(w_s_occ, t_occ)\n",
    "p_emission_end = computeEmissionEnd(w_e_occ, t_occ)\n",
    "    \n",
    "p_transition = computeTransition(w_t, t_occ)\n",
    "print(\"--- %s seconds (Calculate probability - latin) ---\" % round(time.time() - start_time, 2))\n",
    "\n",
    "all_words = getCorpusWords(p_emission)\n",
    "states = getStates(p_transition)\n",
    "\n",
    "start_time = time.time()\n",
    "all_pos = ViterbiHMM(p_emission, p_emission_init, p_transition, query_list, 1)\n",
    "print(\"--- %s seconds (Viterbi, 1st smoothing - latin) ---\" % round(time.time() - start_time, 2))\n",
    "calculateAccuracy(all_pos, w_t_test)\n",
    "\n",
    "start_time = time.time()\n",
    "all_pos = ViterbiHMM(p_emission, p_emission_init, p_transition, query_list, 2)\n",
    "print(\"--- %s seconds (Viterbi, 2nd smoothing - latin) ---\" % round(time.time() - start_time, 2))\n",
    "calculateAccuracy(all_pos, w_t_test)\n",
    "\n",
    "start_time = time.time()\n",
    "all_pos = ViterbiHMM(p_emission, p_emission_init, p_transition, query_list, 3)\n",
    "print(\"--- %s seconds (Viterbi, 3th smoothing - latin) ---\" % round(time.time() - start_time, 2))\n",
    "calculateAccuracy(all_pos, w_t_test)\n",
    "\n",
    "start_time = time.time()\n",
    "all_pos = ViterbiHMM(p_emission, p_emission_init, p_transition, query_list, 4, tag_occ_singleoccWord = tag_occ_singleoccWord, single_occ_words = single_occ_words)\n",
    "print(\"--- %s seconds (Viterbi, 4th smoothing - latin) ---\" % round(time.time() - start_time, 2))\n",
    "calculateAccuracy(all_pos, w_t_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b9b2ca-d5b4-48ea-a108-be78a5087d97",
   "metadata": {},
   "source": [
    "Analogamente a quanto fatto con Viterbi, analizzo i tempi di esecuzione della baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c27bdf3-70d2-421a-bb44-6d71caf8aefc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 32.59 seconds (Baseline - latin) ---\n",
      "Right PoS: 22869\n",
      "Wrong PoS: 1210\n",
      "Accuracy: 0.949748743718593\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "all_pos = Baseline(w_t_occ, query_list)\n",
    "print(\"--- %s seconds (Baseline - latin) ---\" % round(time.time() - start_time, 2))\n",
    "calculateAccuracy(all_pos, w_t_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a3ae12-6b7a-46a0-9cd7-8f24180895de",
   "metadata": {},
   "source": [
    "## Greco "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "98c5ac3a-36f9-49bc-9587-042743582682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 3.37 seconds (Calculate probability - latin) ---\n",
      "--- 135.14 seconds (Viterbi, 1st smoothing - greek) ---\n",
      "Right PoS: 14625\n",
      "Wrong PoS: 6334\n",
      "Accuracy: 0.6977909251395582\n",
      "--- 129.54 seconds (Viterbi, 2nd smoothing - greek) ---\n",
      "Right PoS: 15020\n",
      "Wrong PoS: 5939\n",
      "Accuracy: 0.7166372441433274\n",
      "--- 129.3 seconds (Viterbi, 3th smoothing - greek) ---\n",
      "Right PoS: 14633\n",
      "Wrong PoS: 6326\n",
      "Accuracy: 0.6981726227396345\n",
      "--- 129.86 seconds (Viterbi, 4th smoothing - greek) ---\n",
      "Right PoS: 15062\n",
      "Wrong PoS: 5897\n",
      "Accuracy: 0.7186411565437282\n"
     ]
    }
   ],
   "source": [
    "w_t, w_e, w_s = trainParsing(greek_train_tree_bank)\n",
    "w_t_dev = devParsing(greek_dev_tree_bank)\n",
    "w_t_test, query_list = testParsing(greek_test_tree_bank)\n",
    "\n",
    "tag_occ_singleoccWord, single_occ_words = singleWordDistribution(w_t_dev)\n",
    "\n",
    "w_t_occ, w_s_occ, w_e_occ, t_occ = computeOcc(w_t, w_s, w_e)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "p_emission = computeEmission(w_t_occ, t_occ)\n",
    "p_emission_init = computeEmissionInit(w_s_occ, t_occ)\n",
    "p_emission_end = computeEmissionEnd(w_e_occ, t_occ)\n",
    "    \n",
    "p_transition = computeTransition(w_t, t_occ)\n",
    "print(\"--- %s seconds (Calculate probability - latin) ---\" % round(time.time() - start_time, 2))\n",
    "\n",
    "\n",
    "all_words = getCorpusWords(p_emission)\n",
    "states = getStates(p_transition)\n",
    "\n",
    "start_time = time.time()\n",
    "all_pos = ViterbiHMM(p_emission, p_emission_init, p_transition, query_list, 1)\n",
    "print(\"--- %s seconds (Viterbi, 1st smoothing - greek) ---\" % round(time.time() - start_time, 2))\n",
    "calculateAccuracy(all_pos, w_t_test)\n",
    "\n",
    "start_time = time.time()\n",
    "all_pos = ViterbiHMM(p_emission, p_emission_init, p_transition, query_list, 2)\n",
    "print(\"--- %s seconds (Viterbi, 2nd smoothing - greek) ---\" % round(time.time() - start_time, 2))\n",
    "calculateAccuracy(all_pos, w_t_test)\n",
    "\n",
    "start_time = time.time()\n",
    "all_pos = ViterbiHMM(p_emission, p_emission_init, p_transition, query_list, 3)\n",
    "print(\"--- %s seconds (Viterbi, 3th smoothing - greek) ---\" % round(time.time() - start_time, 2))\n",
    "calculateAccuracy(all_pos, w_t_test)\n",
    "\n",
    "start_time = time.time()\n",
    "all_pos = ViterbiHMM(p_emission, p_emission_init, p_transition, query_list, 4, tag_occ_singleoccWord = tag_occ_singleoccWord, single_occ_words = single_occ_words)\n",
    "print(\"--- %s seconds (Viterbi, 4th smoothing - greek) ---\" % round(time.time() - start_time, 2))\n",
    "calculateAccuracy(all_pos, w_t_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "db8a0719-04a0-43a7-92ec-cb1dd7cce721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 138.1 seconds (Baseline - greek) ---\n",
      "Right PoS: 13541\n",
      "Wrong PoS: 7418\n",
      "Accuracy: 0.6460709003292142\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "all_pos = Baseline(w_t_occ, query_list)\n",
    "print(\"--- %s seconds (Baseline - greek) ---\" % round(time.time() - start_time, 2))\n",
    "calculateAccuracy(all_pos, w_t_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f10d7f-640a-45e5-8168-1ccee3f2e1c6",
   "metadata": {},
   "source": [
    "## Analisi dei risultati\n",
    "### Accuratezza\n",
    "\n",
    "#### Latino\n",
    "\n",
    "Per quanto riguarda la prima lingua presa in considerazione, il latino, abbiamo dei risultati interessanti.\n",
    "Le prestazioni in termini di accuratezza registrate dall'algoritmo *baseline* sono assolutamente notevoli: parliamo del ***95%*** delle parole taggate correttamente.\n",
    "L'applicazione del modello di Markov, in particolare dell'algoritmo di Viterbi, non ha portato a delle migliorie significative, anzi, l'utilizzo delle più generiche tecniche di smoothing portano a una diminuzione dell'accuratezza del 2%.\n",
    "\n",
    "Tabella riassuntiva:\n",
    "\n",
    "|Tecnica di smoothing|Accuratezza|PoS corretti|PoS errati|\n",
    "|:---:|:---:|:---:|:---:|\n",
    "|Baseline|0.94974|22869|1210|\n",
    "|Smoothing 1|0.92831|22353|1726|\n",
    "|Smoothing 2|0.92998|22393|1686|\n",
    "|Smoothing 3|0.93176|22436|1643|\n",
    "|Smoothing 4|0.94173|22676|1403|\n",
    "\n",
    "#### Greco\n",
    "\n",
    "Discorso diverso per quanto riguarda la lingua greca. L'accuratezza di tutte le strategie non è elevata. L'algoritmo base si avvicina al ***65%***.\n",
    "In questo caso l'utilizzo dell'algoritmo di Viterbi ha comportato delle migliorie importanti con un:\n",
    "\n",
    "- +6% applicando la prima e la terza strategia di smoothing\n",
    "- +7% con la seconda e la quarta tecnica di smoothing\n",
    "\n",
    "Nel dettaglio:\n",
    "\n",
    "|Tecnica|Accuratezza|PoS corretti|PoS errati|\n",
    "|:---:|:---:|:---:|:---:|\n",
    "|Baseline|0.64607|13541|7418|\n",
    "|Smoothing 1|0.69779|14625|6334|\n",
    "|Smoothing 2|0.71663|15020|5939|\n",
    "|Smoothing 3|0.69817|14633|6326|\n",
    "|Smoothing 4|0.71864|15062|5897|\n",
    "\n",
    "### Tempi di esecuzione\n",
    "\n",
    "#### Latino \n",
    "\n",
    "La complesità temporale delle varie strategie è allineata: sia la *baseline* che *Viterbi* impiegano all'incirca ***31*** secondi.\n",
    "Nel caso di Viterbi va considerato anche il tempo trascorso per calcolare le probabilità di emissione e di transizione (quest'ultima è calcolata in poco più di 4 secondi).\n",
    "\n",
    "|Tecnica di smoothing|Tempo di esecuzione (s)|\n",
    "|:---:|:---:|\n",
    "|Baseline|32.59|\n",
    "|Smoothing 1|31.06|\n",
    "|Smoothing 2|30.97|\n",
    "|Smoothing 3|31.19|\n",
    "|Smoothing 4|31.11|\n",
    "\n",
    "#### Greco\n",
    "\n",
    "L'andamento si ripete anche per il greco: pressochè paragonabili i tempi di esecuzione di *baseline* e *Viterbi* i quali aumentano notevolmente, se confrontati con il latino, a causa dell'incremento del corpus. Anche in questo caso c'è da aggiungere circa 3 secondi per il calcolo delle probabilità di transizione ed emissione necessarie per *Viterbi*.\n",
    "\n",
    "|Tecnica di smoothing|Tempo di esecuzione (s)|\n",
    "|:---:|:---:|\n",
    "|Baseline|138.1|\n",
    "|Smoothing 1|135.14|\n",
    "|Smoothing 2|129.54|\n",
    "|Smoothing 3|129.3|\n",
    "|Smoothing 4|129.86|\n",
    "\n",
    "### Conclusioni\n",
    "I risultati empirici ottenuti dimostrano che non sempre conviene attuare delle strategie più articolate per risolvere questo tipo di problemi.\n",
    "Il PoS tagger base per il latino, dopo una fase di pre-processing delle parole all'interno del corpus, raggiunte un livello di accuratezza già parecchio elevato. Migliorare questo già ottimo risultato non è scontato.\n",
    "Per il greco, invece, partiamo da una *baseline* decisamente più bassa e che l'algoritmo di Viterbi riesce a migliorare senza troppi problemi.\n",
    "Questo risultato è condizionato dalla presenza di un numero superiore di frasi presenti nel *corpus* train del greco e che consente un più accurato calcolo delle probabilità."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58c914d-eff1-4eb9-81e2-7774d5346f11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
